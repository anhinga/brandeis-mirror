<html>

<head>
<title> Michael Bukatin - Transformer Revolution </title>
</head>

<body>

<h1 align="center"> Michael Bukatin - Transformer Revolution </h1>


<p>July 15, 2020</p>

<p>
At the end of May 2020, the next stage of Transformer revolution began.</p>

<p>
The field experienced a qualitative jump, with the OpenAI presentation
of code generator assistant demo during Microsoft Build 2020 event
on May 20, 2020 (see, e.g. 
<a href="https://twitter.com/matvelloso/status/1263193089310461952">https://twitter.com/matvelloso/status/1263193089310461952</a>)
and then with GPT-3 paper 
<a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a> on May 28, 2020
and <a href="https://openai.com/blog/openai-api/">OpenAI API</a> private beta
on June 11, 2020.</p>

<p>
We are in the middle of July and we have seen reports from enough people using
GPT-3 via that private beta, and we can confidently say that a new epoch
has started, the transition at least as consequential as AlexNet had been
in September-December 2012
has just happened. It's interesting that this coincides with a period of
unusually intense social, political, and economic turbulence 
(somehow, everything is coming to head all at once).
</p>

<p>Technologically speaking, we are at a point when things might start
changing at arbitrarily fast rate at any moment, 
in particular because people are
ready to hybridize all kinds of approaches with Transformers, just
like they hybridized all kinds of approaches with "deep" nets in
recent years. As Jürgen Schmidhuber is saying in recent years,
"we are almost there". Now this has literally become true.</p>

<hr>

<p>See this for a nice collection of usage examples:
<a href="https://twitter.com/xuenay/status/1283312640199196673">https://twitter.com/xuenay/status/1283312640199196673</a></p>

<hr>

<p>March 16, 2024 updates:</p>

<p><a href="https://twitter.com/matvelloso/status/1263193089310461952">https://twitter.com/matvelloso/status/1263193089310461952</a> has been deleted
by the author (although it exists on the Wayback Machine; the tweet author moved from Microsoft to become a VP at Google).</p>

<p>It is probably more convenient to watch this historic video here: <a href="https://www.youtube.com/watch?v=eNhYTLWQFeg">https://www.youtube.com/watch?v=eNhYTLWQFeg</a>
(the conversation with Sam Altman starts at 26:10, the intro to the demo starts at 29:10).</p>
   
<hr>

<p>The next truly big revolution has been the emergence of GPT-4, starting from internal OpenAI releases in the Summer of 2022,
continuing with Bing Chat "Sydney" personality in February 2023, and culminating in the March 14, 2023 official release.</p>

<p>GPT-4 is the first model which possesses "sparks" of true understanding and general competence
(in some sense, deserving a longer essay for a more precise description,
it is a human-equivalent model, with reasonable trade-offs between its capabilities and human capabilities).</p>

<UL>
   <LI>March 14, 2023 GPT-4 Developer Livestream: <a href="https://www.youtube.com/watch?v=outcGtbnMuQ">https://www.youtube.com/watch?v=outcGtbnMuQ</a></LI>
   <LI>GPT-4 page: <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a></LI>
   <LI>Highlights of my GPT-4 experiences: March-September 2023: 
       <a href="https://github.com/anhinga/with-GPT-4/tree/main/March-September-highlights">https://github.com/anhinga/with-GPT-4/tree/main/March-September-highlights</a></LI>
   <LI>Generative autoregressive models are similators:
       <a href="https://github.com/anhinga/2022-notes/tree/main/Generative-autoregressive-models-are-similators">https://github.com/anhinga/2022-notes/tree/main/Generative-autoregressive-models-are-similators</a></LI>
</UL>

</body>
</html>
